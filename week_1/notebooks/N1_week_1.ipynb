{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNch8tftY+pG7Gila4t0xXD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"-zk_YjbKibA0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762050517692,"user_tz":-300,"elapsed":20487,"user":{"displayName":"Ислом Махмудов","userId":"01836210873718254272"}},"outputId":"d9e84214-93dc-4f8f-bf80-de0eaa4ff0d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","project: /content/drive/MyDrive/Colab Notebooks/New_cyber_project\n","dataset: /content/drive/MyDrive/Colab Notebooks/New_cyber_project/dataset\n","week_1 outputs: /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1/outputs\n"]}],"source":["# /colab_notebooks/week1_step1_setup.ipynb\n","\n","import os\n","from google.colab import drive\n","\n","DRIVE_MOUNT_PT = \"/content/drive\"\n","if not os.path.ismount(DRIVE_MOUNT_PT):\n","    drive.mount(DRIVE_MOUNT_PT)\n","\n","PROJECT_ROOT  = f\"{DRIVE_MOUNT_PT}/MyDrive/Colab Notebooks/New_cyber_project\"\n","DATASET_ROOT  = os.path.join(PROJECT_ROOT, \"dataset\")\n","WEEK_ROOT     = os.path.join(PROJECT_ROOT, \"week_1\")\n","WEEK_OUTPUT   = os.path.join(WEEK_ROOT, \"outputs\")\n","WEEK_NB       = os.path.join(WEEK_ROOT, \"notebooks\")\n","\n","INPUT_FOLDERS = {\n","    \"Windows\": os.path.join(DATASET_ROOT, \"Processed_Windows_dataset\"),\n","    \"Linux\":   os.path.join(DATASET_ROOT, \"Processed_Linux_dataset\"),\n","    \"Network\": os.path.join(DATASET_ROOT, \"Processed_Network_dataset\"),\n","    \"IoT\":     os.path.join(DATASET_ROOT, \"Processed_IoT_dataset\"),\n","}\n","\n","os.makedirs(WEEK_OUTPUT, exist_ok=True)\n","os.makedirs(WEEK_NB, exist_ok=True)\n","\n","print(\"project:\", PROJECT_ROOT)\n","print(\"dataset:\", DATASET_ROOT)\n","print(\"week_1 outputs:\", WEEK_OUTPUT)\n"]},{"cell_type":"code","source":["# /colab_notebooks/week1_step2_verify_dirs.ipynb\n","\n","import os\n","\n","required = {\n","    \"PROJECT_ROOT\": PROJECT_ROOT,\n","    \"DATASET_ROOT\": DATASET_ROOT,\n","    \"WEEK_ROOT\": WEEK_ROOT,\n","    \"WEEK_OUTPUT\": WEEK_OUTPUT,\n","    **{f\"INPUT:{k}\": v for k, v in INPUT_FOLDERS.items()},\n","}\n","\n","missing = [name for name, path in required.items() if not os.path.isdir(path)]\n","for name, path in required.items():\n","    flag = \"OK\" if os.path.isdir(path) else \"MISSING\"\n","    print(f\"{flag:8s} {name:14s} -> {path}\")\n","\n","if missing:\n","    raise FileNotFoundError(\"Missing folders: \" + \", \".join(missing))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhB42P6VQBrf","executionInfo":{"status":"ok","timestamp":1762050534996,"user_tz":-300,"elapsed":16,"user":{"displayName":"Ислом Махмудов","userId":"01836210873718254272"}},"outputId":"6fabd813-f348-4162-c211-d84651bf7e15"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["OK       PROJECT_ROOT   -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project\n","OK       DATASET_ROOT   -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project/dataset\n","OK       WEEK_ROOT      -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1\n","OK       WEEK_OUTPUT    -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1/outputs\n","OK       INPUT:Windows  -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project/dataset/Processed_Windows_dataset\n","OK       INPUT:Linux    -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project/dataset/Processed_Linux_dataset\n","OK       INPUT:Network  -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project/dataset/Processed_Network_dataset\n","OK       INPUT:IoT      -> /content/drive/MyDrive/Colab Notebooks/New_cyber_project/dataset/Processed_IoT_dataset\n"]}]},{"cell_type":"code","source":["# /colab_notebooks/week1_step3a_week_structure.ipynb\n","\n","import os\n","\n","# Idempotent creation; separate step for clarity across weeks\n","os.makedirs(WEEK_OUTPUT, exist_ok=True)\n","os.makedirs(WEEK_NB, exist_ok=True)\n","print(\"ready:\", WEEK_OUTPUT, \"|\", WEEK_NB)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGcyJcxKQVsi","executionInfo":{"status":"ok","timestamp":1762050554317,"user_tz":-300,"elapsed":18,"user":{"displayName":"Ислом Махмудов","userId":"01836210873718254272"}},"outputId":"9258b57f-218f-481a-e389-80aa1b47834c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ready: /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1/outputs | /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1/notebooks\n"]}]},{"cell_type":"code","source":["# /colab_notebooks/week1_step3b_inventory_paths.ipynb\n","\n","import os, glob\n","import pandas as pd\n","from datetime import datetime\n","\n","ALLOWED_EXTS = {\".csv\", \".parquet\"}\n","\n","def _ext(p): return os.path.splitext(p)[1].lower()\n","def _mb(n):  return round(((n or 0)/1024/1024), 3)\n","\n","rows = []\n","for domain, root in INPUT_FOLDERS.items():\n","    for p in glob.glob(os.path.join(root, \"**\", \"*\"), recursive=True):\n","        if not os.path.isfile(p):\n","            continue\n","        e = _ext(p)\n","        if e not in ALLOWED_EXTS:\n","            continue\n","        try:\n","            st = os.stat(p)\n","            size_b = st.st_size\n","            mtime  = datetime.fromtimestamp(st.st_mtime).isoformat(timespec=\"seconds\")\n","        except FileNotFoundError:\n","            size_b, mtime = None, None\n","        rows.append({\n","            \"domain\": domain,\n","            \"path\": p,\n","            \"extension\": e,\n","            \"size_bytes\": size_b,\n","            \"size_mb\": _mb(size_b),\n","            \"modified\": mtime,\n","        })\n","\n","inv = pd.DataFrame(rows).sort_values([\"domain\",\"extension\",\"path\"]).reset_index(drop=True)\n","out_csv = os.path.join(WEEK_OUTPUT, \"data_inventory_paths.csv\")\n","inv.to_csv(out_csv, index=False)\n","\n","print(\"inventory:\", out_csv, \"| files:\", len(inv))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-WMBRT1ASNVH","executionInfo":{"status":"ok","timestamp":1762050568330,"user_tz":-300,"elapsed":2148,"user":{"displayName":"Ислом Махмудов","userId":"01836210873718254272"}},"outputId":"853301e0-b308-4bb0-e9b0-63620ba9de86"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["inventory: /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1/outputs/data_inventory_paths.csv | files: 28\n"]}]},{"cell_type":"code","source":["# /colab_notebooks/week1_step4_schema_preview.ipynb\n","\n","from __future__ import annotations\n","\n","import os, json, re\n","from typing import List, Dict, Any, Optional\n","import pandas as pd\n","\n","INVENTORY_CSV = os.path.join(WEEK_OUTPUT, \"data_inventory_paths.csv\")\n","SCHEMA_JSON   = os.path.join(WEEK_OUTPUT, \"schema_preview.json\")\n","ERRORS_CSV    = os.path.join(WEEK_OUTPUT, \"schema_errors.csv\")\n","\n","if not os.path.isfile(INVENTORY_CSV):\n","    raise FileNotFoundError(f\"Required file not found: {INVENTORY_CSV}\")\n","\n","inv = pd.read_csv(INVENTORY_CSV)\n","if inv.empty:\n","    raise ValueError(\"Inventory contains no entries.\")\n","\n","MAX_ROWS = 10_000\n","TARGET_RE = re.compile(r\"^(label|labels|target|class|attack_cat|type)$\", re.I)\n","\n","def read_sample(path: str, ext: str, nrows: int) -> Optional[pd.DataFrame]:\n","    try:\n","        if ext == \".csv\":\n","            return pd.read_csv(path, nrows=nrows, low_memory=True)\n","        if ext == \".parquet\":\n","            return pd.read_parquet(path).head(nrows)\n","        return None\n","    except Exception:\n","        return None\n","\n","def candidate_targets(cols: List[str]) -> List[str]:\n","    return [c for c in cols if TARGET_RE.match(c)]\n","\n","schema_records: List[Dict[str, Any]] = []\n","error_records: List[Dict[str, Any]] = []\n","\n","for _, r in inv.iterrows():\n","    path = str(r[\"path\"]); ext = str(r[\"extension\"]).lower(); dom = str(r[\"domain\"])\n","    df = read_sample(path, ext, MAX_ROWS)\n","    if df is None or df.empty:\n","        error_records.append({\"domain\": dom, \"path\": path, \"extension\": ext, \"error\": \"ReadError\"})\n","        continue\n","    cols = list(df.columns)\n","    schema_records.append({\n","        \"domain\": dom,\n","        \"path\": path,\n","        \"extension\": ext,\n","        \"sample_rows\": int(min(len(df), MAX_ROWS)),\n","        \"ncols\": int(len(cols)),\n","        \"columns\": cols,\n","        \"dtypes\": {c: str(df[c].dtype) for c in cols},\n","        \"candidate_targets\": candidate_targets(cols),\n","    })\n","\n","with open(SCHEMA_JSON, \"w\") as f:\n","    json.dump(schema_records, f, indent=2)\n","if error_records:\n","    pd.DataFrame(error_records).to_csv(ERRORS_CSV, index=False)\n","\n","print(\"schema:\", SCHEMA_JSON, \"| ok:\", len(schema_records), \"| errors:\", len(error_records))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPmQ4LQ9Sw0t","executionInfo":{"status":"ok","timestamp":1762050600224,"user_tz":-300,"elapsed":17347,"user":{"displayName":"Ислом Махмудов","userId":"01836210873718254272"}},"outputId":"02b9ccf6-065f-4284-9f68-4710577666e0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2053423337.py:26: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,22,27,30,39,46,47,50,52,53,55,57,59,60,61,62,63,72,73,74,75,77,80,81,85,96,99,101,102,103,104,106,107,108,110,112,113,114,115,116,117,118,119,120,121,122,123,124) have mixed types. Specify dtype option on import or set low_memory=False.\n","  return pd.read_csv(path, nrows=nrows, low_memory=True)\n","/tmp/ipython-input-2053423337.py:26: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,47,48,49,50,51,52,59,60,61,65,66,67,71,72,73,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,104,105,106,107,109,112,113,116,127,130,132) have mixed types. Specify dtype option on import or set low_memory=False.\n","  return pd.read_csv(path, nrows=nrows, low_memory=True)\n"]},{"output_type":"stream","name":"stdout","text":["schema: /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1/outputs/schema_preview.json | ok: 28 | errors: 0\n"]}]},{"cell_type":"code","source":["# /colab_notebooks/week1_step5_summary.ipynb\n","\n","import os, json\n","import pandas as pd\n","\n","INVENTORY_CSV = os.path.join(WEEK_OUTPUT, \"data_inventory_paths.csv\")\n","SCHEMA_JSON   = os.path.join(WEEK_OUTPUT, \"schema_preview.json\")\n","ERRORS_CSV    = os.path.join(WEEK_OUTPUT, \"schema_errors.csv\")\n","OUT_CSV       = os.path.join(WEEK_OUTPUT, \"summary.csv\")\n","\n","if not os.path.isfile(INVENTORY_CSV):\n","    raise FileNotFoundError(f\"Required file not found: {INVENTORY_CSV}\")\n","if not os.path.isfile(SCHEMA_JSON):\n","    raise FileNotFoundError(f\"Required file not found: {SCHEMA_JSON}\")\n","\n","inv = pd.read_csv(INVENTORY_CSV)\n","schema_ok = pd.DataFrame(json.load(open(SCHEMA_JSON))) if os.path.getsize(SCHEMA_JSON) > 2 else pd.DataFrame()\n","schema_err = pd.read_csv(ERRORS_CSV) if os.path.isfile(ERRORS_CSV) else pd.DataFrame(columns=[\"domain\",\"path\",\"extension\",\"error\"])\n","\n","if schema_ok.empty:\n","    schema_ok = pd.DataFrame(columns=[\"domain\",\"path\",\"extension\",\"candidate_targets\",\"ncols\",\"sample_rows\"])\n","\n","def has_target(v) -> bool:\n","    if isinstance(v, list):\n","        return len(v) > 0\n","    if isinstance(v, str):\n","        return v.strip() not in (\"[]\", \"\", \"nan\")\n","    return False\n","\n","schema_ok[\"has_target\"] = schema_ok[\"candidate_targets\"].apply(has_target)\n","\n","totals = inv.groupby(\"domain\").size().rename(\"total_files\").to_frame()\n","okc    = schema_ok.groupby(\"domain\").size().rename(\"ok_files\").to_frame()\n","errs   = schema_err.groupby(\"domain\").size().rename(\"error_files\").to_frame()\n","with_y = schema_ok.groupby(\"domain\")[\"has_target\"].sum().rename(\"files_with_target\").to_frame()\n","avg_nc = schema_ok.groupby(\"domain\")[\"ncols\"].mean().round(2).rename(\"avg_ncols\").to_frame()\n","med_sr = schema_ok.groupby(\"domain\")[\"sample_rows\"].median().rename(\"median_sample_rows\").to_frame()\n","\n","summary = (totals.join(okc, how=\"left\")\n","                 .join(errs, how=\"left\")\n","                 .join(with_y, how=\"left\")\n","                 .join(avg_nc, how=\"left\")\n","                 .join(med_sr, how=\"left\")\n","                 .fillna(0)\n","                 .reset_index())\n","\n","summary[\"ok_files\"] = summary[\"ok_files\"].astype(int)\n","summary[\"error_files\"] = summary[\"error_files\"].astype(int)\n","summary[\"files_with_target\"] = summary[\"files_with_target\"].astype(int)\n","summary[\"pct_with_target\"] = (summary[\"files_with_target\"] / summary[\"total_files\"] * 100).round(2)\n","\n","cols = [\"domain\",\"total_files\",\"ok_files\",\"error_files\",\"files_with_target\",\"pct_with_target\",\"avg_ncols\",\"median_sample_rows\"]\n","summary = summary[cols]\n","summary.to_csv(OUT_CSV, index=False)\n","\n","print(\"summary:\", OUT_CSV)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGWLplbKTiya","executionInfo":{"status":"ok","timestamp":1762050616189,"user_tz":-300,"elapsed":512,"user":{"displayName":"Ислом Махмудов","userId":"01836210873718254272"}},"outputId":"9526b176-6d40-48c7-d340-2cf0c6c07cf7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["summary: /content/drive/MyDrive/Colab Notebooks/New_cyber_project/week_1/outputs/summary.csv\n"]}]},{"cell_type":"code","source":["# /colab_notebooks/week2_step3_column_profile.ipynb\n","\n","from __future__ import annotations\n","\n","import os\n","from collections import Counter, defaultdict\n","from dataclasses import dataclass\n","from typing import Dict, Iterable, List, Optional\n","\n","import pandas as pd\n","\n","DRIVE_MOUNT_PT = \"/content/drive\"\n","PROJECT_ROOT   = f\"{DRIVE_MOUNT_PT}/MyDrive/Colab Notebooks/New_cyber_project\"\n","W1_OUT         = os.path.join(PROJECT_ROOT, \"week_1\", \"outputs\")\n","W2_OUT         = os.path.join(PROJECT_ROOT, \"week_2\", \"outputs\")\n","\n","INVENTORY_CSV       = os.path.join(W1_OUT, \"data_inventory_paths.csv\")\n","COLUMN_PROFILE_CSV  = os.path.join(W2_OUT, \"column_profile.csv\")\n","DTYPE_SUMMARY_CSV   = os.path.join(W2_OUT, \"dtype_summary.csv\")\n","\n","MAX_SAMPLE_ROWS = 10_000  # as requested\n","\n","@dataclass(frozen=True)\n","class FileEntry:\n","    domain: str\n","    path: str\n","    extension: str\n","\n","@dataclass\n","class FileSchema:\n","    domain: str\n","    path: str\n","    columns: List[str]\n","    dtypes: Dict[str, str]\n","\n","def ensure_inputs() -> None:\n","    if not os.path.isfile(INVENTORY_CSV):\n","        raise FileNotFoundError(f\"Required file not found: {INVENTORY_CSV}\")\n","    os.makedirs(W2_OUT, exist_ok=True)\n","\n","def read_inventory() -> List[FileEntry]:\n","    df = pd.read_csv(INVENTORY_CSV)\n","    if df.empty:\n","        raise ValueError(\"Inventory contains no entries.\")\n","    return [\n","        FileEntry(str(r[\"domain\"]), str(r[\"path\"]), str(r[\"extension\"]).lower())\n","        for _, r in df.iterrows()\n","    ]\n","\n","def read_sample(path: str, extension: str, nrows: int) -> Optional[pd.DataFrame]:\n","    try:\n","        if extension == \".csv\":\n","            return pd.read_csv(path, nrows=nrows, low_memory=True)\n","        if extension == \".parquet\":\n","            return pd.read_parquet(path).head(nrows)\n","        return None\n","    except Exception:\n","        return None\n","\n","def infer_file_schema(e: FileEntry) -> Optional[FileSchema]:\n","    df = read_sample(e.path, e.extension, MAX_SAMPLE_ROWS)\n","    if df is None or df.empty:\n","        return None\n","    cols = list(df.columns)\n","    dtypes = {c: str(df[c].dtype) for c in cols}\n","    return FileSchema(e.domain, e.path, cols, dtypes)\n","\n","def collect_schemas(entries: Iterable[FileEntry]) -> List[FileSchema]:\n","    out: List[FileSchema] = []\n","    for e in entries:\n","        fs = infer_file_schema(e)\n","        if fs is not None:\n","            out.append(fs)\n","    if not out:\n","        raise ValueError(\"No readable files were found during sampling.\")\n","    return out\n","\n","def build_column_profile(schemas: List[FileSchema]) -> pd.DataFrame:\n","    by_domain_files = defaultdict(set)\n","    by_domain_col_files = defaultdict(lambda: defaultdict(set))\n","    by_domain_col_dtype = defaultdict(lambda: defaultdict(Counter))\n","\n","    for fs in schemas:\n","        by_domain_files[fs.domain].add(fs.path)\n","        for c in fs.columns:\n","            by_domain_col_files[fs.domain][c].add(fs.path)\n","            by_domain_col_dtype[fs.domain][c].update([fs.dtypes.get(c, \"unknown\")])\n","\n","    rows: List[Dict[str, object]] = []\n","    for dom, files in by_domain_files.items():\n","        total = len(files)\n","        for col, file_set in by_domain_col_files[dom].items():\n","            modal_dtype = by_domain_col_dtype[dom][col].most_common(1)[0][0]\n","            rows.append({\n","                \"domain\": dom,\n","                \"column\": col,\n","                \"files_with_column\": len(file_set),\n","                \"total_files_in_domain\": total,\n","                \"pct_coverage\": round(len(file_set) / total * 100.0, 2) if total else 0.0,\n","                \"modal_dtype\": modal_dtype,\n","            })\n","\n","    df = pd.DataFrame(rows)\n","    if df.empty:\n","        df = pd.DataFrame(columns=[\"domain\",\"column\",\"files_with_column\",\"total_files_in_domain\",\"pct_coverage\",\"modal_dtype\"])\n","    return df.sort_values([\"domain\",\"pct_coverage\",\"column\"], ascending=[True, False, True]).reset_index(drop=True)\n","\n","def build_dtype_summary(schemas: List[FileSchema]) -> pd.DataFrame:\n","    by_domain = defaultdict(Counter)\n","    for fs in schemas:\n","        by_domain[fs.domain].update(fs.dtypes.values())\n","    rows = [{\"domain\": d, \"dtype\": t, \"count\": int(c)} for d, ctr in by_domain.items() for t, c in ctr.most_common()]\n","    df = pd.DataFrame(rows)\n","    if df.empty:\n","        df = pd.DataFrame(columns=[\"domain\",\"dtype\",\"count\"])\n","    return df.sort_values([\"domain\",\"count\"], ascending=[True, False]).reset_index(drop=True)\n","\n","def main() -> None:\n","    ensure_inputs()\n","    entries = read_inventory()\n","    schemas = collect_schemas(entries)\n","    column_profile = build_column_profile(schemas)\n","    dtype_summary = build_dtype_summary(schemas)\n","    column_profile.to_csv(COLUMN_PROFILE_CSV, index=False)\n","    dtype_summary.to_csv(DTYPE_SUMMARY_CSV, index=False)\n","    print(f\"column_profile: {COLUMN_PROFILE_CSV}\")\n","    print(f\"dtype_summary:  {DTYPE_SUMMARY_CSV}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"KXRKzYscbFe9"},"execution_count":null,"outputs":[]}]}